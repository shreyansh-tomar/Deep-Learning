{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMFYbJ1xK/iraDsHfy7eQHL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyansh-tomar/Deep-Learning/blob/master/Sentiment_Analysis/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYHhbCGDJ_Wq",
        "colab_type": "text"
      },
      "source": [
        "## **Curating the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czcYNjljFvO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pretty_print_review_and_label(i):\n",
        "    print(labels[i] + \"\\t:\\t\" + reviews[i][:80] + \"...\")\n",
        "\n",
        "g = open('reviews.txt','r') # What we know!\n",
        "reviews = list(map(lambda x:x[:-1],g.readlines()))\n",
        "g.close()\n",
        "\n",
        "g = open('labels.txt','r') # What we WANT to know!\n",
        "labels = list(map(lambda x:x[:-1].upper(),g.readlines()))\n",
        "g.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSdgYpm3Jz2J",
        "colab_type": "code",
        "outputId": "56ebbf0d-85d3-46fa-c6cd-4d53b2185240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(reviews)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ampPBHAiJ5dy",
        "colab_type": "code",
        "outputId": "19ed3fb2-6691-442f-b01a-0283a7fbf6fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "reviews[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlTSSThTKLTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piwo_ATNLRcZ",
        "colab_type": "text"
      },
      "source": [
        "# Developing a predictive theory!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqG52kgOLZJ9",
        "colab_type": "code",
        "outputId": "879c4534-176b-4de7-8808-a9a37c6924a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "print(\"labels.txt:\\t reviews.txt\\n\")\n",
        "pretty_print_review_and_label(2137)\n",
        "pretty_print_review_and_label(12816)\n",
        "pretty_print_review_and_label(6267)\n",
        "pretty_print_review_and_label(21934)\n",
        "pretty_print_review_and_label(5297)\n",
        "pretty_print_review_and_label(4998)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels.txt:\t reviews.txt\n",
            "\n",
            "NEGATIVE\t:\tthis movie is terrible but it has some good effects .  ...\n",
            "POSITIVE\t:\tadrian pasdar is excellent is this film . he makes a fascinating woman .  ...\n",
            "NEGATIVE\t:\tcomment this movie is impossible . is terrible  very improbable  bad interpretat...\n",
            "POSITIVE\t:\texcellent episode movie ala pulp fiction .  days   suicides . it doesnt get more...\n",
            "NEGATIVE\t:\tif you haven  t seen this  it  s terrible . it is pure trash . i saw this about ...\n",
            "POSITIVE\t:\tthis schiffer guy is a real genius  the movie is of excellent quality and both e...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmViE248L7lP",
        "colab_type": "text"
      },
      "source": [
        "**Note:**\n",
        "*These seems to be really Polarised examples, but what I'll be really looking for is what creates a correlation between my reviews and labels dataset!\n",
        "One way is by taking the entire review as sort of what this dataset is.. Well, it's very predictive. Unfortunately, we only saw it once & I can likely expect that most reviews we will see be original. Many people will definitely say some straight forward things like \"The movie is terrible\", etc. but most reviews have some nuance. They have particular choice of words & sequence that won't be duplicated very often. So, training a NN on the whole review might not work very well.*\n",
        "**Great Correlation but poor Generalisation!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KgJXKeZOfXu",
        "colab_type": "text"
      },
      "source": [
        "**Proposed theory:**\n",
        "In -ve examples we see words like terrible, trash, bad, improbable,etc.. whereas in +ve examples we see words like execellent, genius, etc..\n",
        "that might have some correlation b/w Labels and Reviews.So, maybe it can be the counts of different kinds of words occuring in the reviews..\n",
        "# Let's validate our theory!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op3AP--sMfEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIHTEcG2XEP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create three Counter objects to store positive, negative and total counts\n",
        "positive_counts = Counter()\n",
        "negative_counts = Counter()\n",
        "total_counts = Counter()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4xJRhafXNPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(reviews)):\n",
        "    if labels[i] == \"POSITIVE\":\n",
        "        for word in reviews[i].split(\" \"):\n",
        "            positive_counts[word] += 1        \n",
        "            total_counts[word] += 1\n",
        "    else:\n",
        "         for word in reviews[i].split(\" \"):\n",
        "            negative_counts[word] += 1\n",
        "            total_counts[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GMpiHDJXPuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "positive_counts.most_common()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O43MpevPX5AI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "negative_counts.most_common()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfT19fzKYXvK",
        "colab_type": "text"
      },
      "source": [
        "Instead of finding the most common words in positive or negative reviews, what I really want are the words found in positive reviews more often than in negative reviews, and vice versa. To accomplish this, I'll need to calculate the **ratios** of word usage between positive and negative reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZsciTQuX_Qm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos_neg_ratios = Counter()\n",
        "\n",
        "for term, cnt in list(total_counts.most_common()):\n",
        "    if(cnt > 100):\n",
        "        pos_neg_ratio = positive_counts[term]/float(negative_counts[term]+1)\n",
        "        pos_neg_ratios[term] = pos_neg_ratio\n",
        "\n",
        "for word, ratio in pos_neg_ratios.most_common():\n",
        "    if(ratio > 1):\n",
        "        pos_neg_ratios[word] = np.log(ratio)\n",
        "    else:\n",
        "        pos_neg_ratios[word] = -np.log(1/(ratio + 0.01))\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekShdOc8J6o2",
        "colab_type": "code",
        "outputId": "48435dc2-4be1-4ef5-bd50-1c025640ff62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(\"Pos-to-neg ratio for 'the' = {}\".format(pos_neg_ratios[\"the\"]))\n",
        "print(\"Pos-to-neg ratio for 'amazing' = {}\".format(pos_neg_ratios[\"amazing\"]))\n",
        "print(\"Pos-to-neg ratio for 'terrible' = {}\".format(pos_neg_ratios[\"terrible\"]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pos-to-neg ratio for 'the' = 0.05902269426102881\n",
            "Pos-to-neg ratio for 'amazing' = 1.3919815802404802\n",
            "Pos-to-neg ratio for 'terrible' = -1.6742829939664696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPCB8oR9KBlJ",
        "colab_type": "text"
      },
      "source": [
        "Looking closely at the values you just calculated, we see the following:\n",
        "\n",
        "\n",
        "*   Words that you would expect to see more often in positive reviews – like \"amazing\" – have a ratio greater than 1. The more skewed a word is toward postive, the farther from 1 its positive-to-negative ratio will be.\n",
        "*   Words that you would expect to see more often in negative reviews – like \"terrible\" – have positive values that are less than 1. The more skewed a word is toward negative, the closer to zero its positive-to-negative ratio will be\n",
        "\n",
        "*   Neutral words, which don't really convey any sentiment because you would expect to see them in all sorts of reviews – like \"the\" – have values very close to 1. A perfectly neutral word – one that was used in exactly the same number of positive reviews as negative reviews – would be almost exactly 1. The +1 we suggested you add to the denominator slightly biases words toward negative, but it won't matter because it will be a tiny bias and later we'll be ignoring words that are too close to neutral anyway.\n",
        "\n",
        "\n",
        "Ok, the ratios tell us which words are used more often in postive or negative reviews, but the specific values we've calculated are a bit difficult to work with. A very positive word like \"amazing\" has a value above 4, whereas a very negative word like \"terrible\" has a value around 0.18. Those values aren't easy to compare for a couple of reasons:\n",
        "\n",
        "* Right now, 1 is considered neutral, but the absolute value of the postive-to-negative rations of very postive words is larger than the absolute value of the ratios for the very negative words. So there is no way to directly compare two numbers and see if one word conveys the same magnitude of positive sentiment as another word conveys negative sentiment. So we should center all the values around netural so the absolute value from neutral of the postive-to-negative ratio for a word would indicate how much sentiment (positive or negative) that word conveys.\n",
        "* When comparing absolute values it's easier to do that around zero than one. \n",
        "To fix these issues, we'll convert all of our ratios to new values using logarithms.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5JcJJv8J-GN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}