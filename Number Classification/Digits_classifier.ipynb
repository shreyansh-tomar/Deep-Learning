{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST handwritten digit classification problem is a standard dataset used in Computer Vision and Deep Learing Models.\n",
    "Here we will harness the power of Neural Networks to build a deep learning model and train it for recognising __Handwritten Digits__. <br>\n",
    "__NOTE__:The recognised digit is shown as a plot(digits vs probability).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch import optim\n",
    "\n",
    "#Defining a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,),(0.5,)),                    \n",
    "            ])\n",
    "#Downloading and training the dataset\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train= True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Backward:\n",
      " None\n",
      "After Backward:\n",
      " tensor([[-2.8558e-05, -2.8558e-05, -2.8558e-05,  ..., -2.8558e-05,\n",
      "         -2.8558e-05, -2.8558e-05],\n",
      "        [-1.7204e-03, -1.7204e-03, -1.7204e-03,  ..., -1.7204e-03,\n",
      "         -1.7204e-03, -1.7204e-03],\n",
      "        [ 5.4019e-04,  5.4019e-04,  5.4019e-04,  ...,  5.4019e-04,\n",
      "          5.4019e-04,  5.4019e-04],\n",
      "        ...,\n",
      "        [-2.2437e-04, -2.2437e-04, -2.2437e-04,  ..., -2.2437e-04,\n",
      "         -2.2437e-04, -2.2437e-04],\n",
      "        [ 6.0656e-04,  6.0656e-04,  6.0656e-04,  ...,  6.0656e-04,\n",
      "          6.0656e-04,  6.0656e-04],\n",
      "        [ 4.8198e-04,  4.8198e-04,  4.8198e-04,  ...,  4.8198e-04,\n",
      "          4.8198e-04,  4.8198e-04]])\n"
     ]
    }
   ],
   "source": [
    "#Building a feed-forward model\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim = 1))\n",
    "#Defining Loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "#Getting the data\n",
    "images, lables = next(iter(trainloader))\n",
    "\n",
    "#Flatening the images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "#forward pass and get our probabilities(because of Softmax use in model)\n",
    "logpbs = model(images)\n",
    "\n",
    "#Calculating loss\n",
    "loss = criterion(logpbs, lables)\n",
    "print('Before Backward:\\n', model[0].weight.grad)\n",
    "loss.backward()\n",
    "print('After Backward:\\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[-1.0889e-02, -7.2019e-03, -4.6896e-04,  ...,  6.6161e-06,\n",
      "         -4.1888e-03,  2.5887e-02],\n",
      "        [-2.8772e-02, -3.1041e-02,  1.9158e-03,  ...,  2.4674e-02,\n",
      "         -6.5933e-03,  3.0679e-02],\n",
      "        [-3.0857e-02,  1.3269e-02,  1.1038e-05,  ...,  1.4617e-02,\n",
      "          6.7315e-03,  2.4957e-02],\n",
      "        ...,\n",
      "        [ 8.3062e-04, -2.3143e-02, -3.2421e-02,  ..., -1.0852e-02,\n",
      "         -3.4783e-02, -2.0181e-02],\n",
      "        [-3.0668e-02,  2.0341e-04, -3.3294e-02,  ...,  2.3626e-02,\n",
      "          3.1622e-02,  2.9218e-02],\n",
      "        [-2.0081e-02,  2.8791e-02,  2.9054e-02,  ..., -6.0315e-03,\n",
      "         -1.8485e-02,  5.0280e-03]], requires_grad=True)\n",
      "Final weights -  tensor([[-1.2269e-03, -1.2269e-03, -1.2269e-03,  ..., -1.2269e-03,\n",
      "         -1.2269e-03, -1.2269e-03],\n",
      "        [-1.0214e-03, -1.0214e-03, -1.0214e-03,  ..., -1.0214e-03,\n",
      "         -1.0214e-03, -1.0214e-03],\n",
      "        [-6.2344e-04, -6.2344e-04, -6.2344e-04,  ..., -6.2345e-04,\n",
      "         -6.2345e-04, -6.2345e-04],\n",
      "        ...,\n",
      "        [ 7.8645e-05,  7.8645e-05,  7.8645e-05,  ...,  7.8645e-05,\n",
      "          7.8645e-05,  7.8645e-05],\n",
      "        [-3.4162e-04, -3.4162e-04, -3.4162e-04,  ..., -3.4162e-04,\n",
      "         -3.4162e-04, -3.4162e-04],\n",
      "        [ 1.7276e-03,  1.7276e-03,  1.7276e-03,  ...,  1.7276e-03,\n",
      "          1.7276e-03,  1.7276e-03]])\n",
      "Final weights -  Parameter containing:\n",
      "tensor([[-1.0877e-02, -7.1896e-03, -4.5669e-04,  ...,  1.8885e-05,\n",
      "         -4.1765e-03,  2.5899e-02],\n",
      "        [-2.8762e-02, -3.1031e-02,  1.9260e-03,  ...,  2.4684e-02,\n",
      "         -6.5831e-03,  3.0690e-02],\n",
      "        [-3.0851e-02,  1.3275e-02,  1.7272e-05,  ...,  1.4624e-02,\n",
      "          6.7377e-03,  2.4963e-02],\n",
      "        ...,\n",
      "        [ 8.2983e-04, -2.3144e-02, -3.2422e-02,  ..., -1.0853e-02,\n",
      "         -3.4784e-02, -2.0182e-02],\n",
      "        [-3.0664e-02,  2.0682e-04, -3.3290e-02,  ...,  2.3630e-02,\n",
      "          3.1625e-02,  2.9221e-02],\n",
      "        [-2.0099e-02,  2.8774e-02,  2.9037e-02,  ..., -6.0487e-03,\n",
      "         -1.8502e-02,  5.0107e-03]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
    "\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "logpbs = model(images)\n",
    "loss = criterion(logpbs, labels)\n",
    "loss.backward()\n",
    "print('Final weights - ', model[0].weight.grad)\n",
    "\n",
    "optimizer.step()\n",
    "print('Final weights - ', model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: , 1.9280258549301863\n",
      "Training loss: , 0.9204785964890584\n",
      "Training loss: , 0.5509008905336038\n",
      "Training loss: , 0.4427621492000023\n",
      "Training loss: , 0.3925962892136594\n",
      "Training loss: , 0.3641432217681713\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim = 1))\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr = 0.003)\n",
    "\n",
    "epochs = 6\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        print(f\"Training loss: , {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
