{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST handwritten digit classification problem is a standard dataset used in Computer Vision and Deep Learing Models.\n",
    "Here we will harness the power of Neural Networks to build a deep learning model and train it for recognising __Handwritten Digits__. <br>\n",
    "__NOTE__:The recognised digit is shown as a plot(digits vs probability).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch import optim\n",
    "\n",
    "#Defining a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,),(0.5,)),                    \n",
    "            ])\n",
    "#Downloading and training the dataset\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train= True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Backward:\n",
      " None\n",
      "After Backward:\n",
      " tensor([[ 2.4983e-03,  2.4983e-03,  2.4983e-03,  ...,  2.4983e-03,\n",
      "          2.4983e-03,  2.4983e-03],\n",
      "        [-1.7430e-04, -1.7430e-04, -1.7430e-04,  ..., -1.7430e-04,\n",
      "         -1.7430e-04, -1.7430e-04],\n",
      "        [-4.1464e-03, -4.1464e-03, -4.1464e-03,  ..., -4.1464e-03,\n",
      "         -4.1464e-03, -4.1464e-03],\n",
      "        ...,\n",
      "        [-3.7097e-05, -3.7097e-05, -3.7097e-05,  ..., -3.7097e-05,\n",
      "         -3.7097e-05, -3.7097e-05],\n",
      "        [-5.6831e-03, -5.6831e-03, -5.6831e-03,  ..., -5.6831e-03,\n",
      "         -5.6831e-03, -5.6831e-03],\n",
      "        [ 7.6225e-04,  7.6225e-04,  7.6225e-04,  ...,  7.6225e-04,\n",
      "          7.6225e-04,  7.6225e-04]])\n"
     ]
    }
   ],
   "source": [
    "#Building a feed-forward model\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim = 1))\n",
    "#Defining Loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "#Getting the data\n",
    "images, lables = next(iter(trainloader))\n",
    "\n",
    "#Flatening the images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "#forward pass and get our probabilities(because of Softmax use in model)\n",
    "logpbs = model(images)\n",
    "\n",
    "#Calculating loss\n",
    "loss = criterion(logpbs, lables)\n",
    "print('Before Backward:\\n', model[0].weight.grad)\n",
    "loss.backward()\n",
    "print('After Backward:\\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[-0.0355, -0.0229, -0.0150,  ...,  0.0268, -0.0013,  0.0128],\n",
      "        [ 0.0008, -0.0145, -0.0158,  ..., -0.0068, -0.0162, -0.0176],\n",
      "        [-0.0126,  0.0258,  0.0253,  ..., -0.0285, -0.0033, -0.0321],\n",
      "        ...,\n",
      "        [ 0.0290,  0.0094,  0.0014,  ...,  0.0097, -0.0104, -0.0270],\n",
      "        [-0.0008, -0.0201, -0.0252,  ...,  0.0176,  0.0107, -0.0357],\n",
      "        [ 0.0006, -0.0253,  0.0301,  ...,  0.0320, -0.0110,  0.0161]],\n",
      "       requires_grad=True)\n",
      "Final weights -  tensor([[ 0.0010,  0.0010,  0.0010,  ...,  0.0010,  0.0010,  0.0010],\n",
      "        [-0.0004, -0.0004, -0.0004,  ..., -0.0004, -0.0004, -0.0004],\n",
      "        [-0.0014, -0.0014, -0.0014,  ..., -0.0014, -0.0014, -0.0014],\n",
      "        ...,\n",
      "        [ 0.0006,  0.0006,  0.0006,  ...,  0.0006,  0.0006,  0.0006],\n",
      "        [ 0.0014,  0.0014,  0.0014,  ...,  0.0014,  0.0014,  0.0014],\n",
      "        [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
    "\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "logpbs = model(images)\n",
    "loss = criterion(logpbs, labels)\n",
    "loss.backward()\n",
    "print('Final weights - ', model[0].weight.grad)\n",
    "\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
